{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Chapter 1: Introduction to Physical AI","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robotics-book/docs/chapter-01-introduction-to-physical-ai/lesson-1-1-what-is-physical-ai","label":"Lesson 1.1: What is Physical AI","docId":"chapter-01-introduction-to-physical-ai/lesson-1-1-what-is-physical-ai","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-01-introduction-to-physical-ai/lesson-1-2-embodied-intelligence","label":"Lesson 1.2: Embodied Intelligence","docId":"chapter-01-introduction-to-physical-ai/lesson-1-2-embodied-intelligence","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-01-introduction-to-physical-ai/lesson-1-3-course-overview","label":"Lesson 1.3: Course Overview & Learning Outcomes","docId":"chapter-01-introduction-to-physical-ai/lesson-1-3-course-overview","unlisted":false}]},{"type":"category","label":"Chapter 2: Robotic Nervous System (ROS 2)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robotics-book/docs/chapter-02-robotic-nervous-system-ros-2/lesson-2-1-ros-2-architecture","label":"Lesson 2.1: ROS 2 Architecture","docId":"chapter-02-robotic-nervous-system-ros-2/lesson-2-1-ros-2-architecture","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-02-robotic-nervous-system-ros-2/lesson-2-2-nodes-topics-services-actions","label":"Lesson 2.2: Nodes, Topics, Services, Actions","docId":"chapter-02-robotic-nervous-system-ros-2/lesson-2-2-nodes-topics-services-actions","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-02-robotic-nervous-system-ros-2/lesson-2-3-python-integration","label":"Lesson 2.3: Python Integration","docId":"chapter-02-robotic-nervous-system-ros-2/lesson-2-3-python-integration","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-02-robotic-nervous-system-ros-2/lesson-2-4-urdf-for-humanoids","label":"Lesson 2.4: URDF for Humanoids","docId":"chapter-02-robotic-nervous-system-ros-2/lesson-2-4-urdf-for-humanoids","unlisted":false}]},{"type":"category","label":"Chapter 3: Digital Twin (Gazebo & Unity)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robotics-book/docs/chapter-03-digital-twin-gazebo-unity/lesson-3-1-gazebo-simulation-basics","label":"Lesson 3.1: Gazebo Simulation Basics","docId":"chapter-03-digital-twin-gazebo-unity/lesson-3-1-gazebo-simulation-basics","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-03-digital-twin-gazebo-unity/lesson-3-2-sensor-simulation","label":"Lesson 3.2: Sensor Simulation (LiDAR, Cameras, IMU)","docId":"chapter-03-digital-twin-gazebo-unity/lesson-3-2-sensor-simulation","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-03-digital-twin-gazebo-unity/lesson-3-3-high-fidelity-rendering-with-unity","label":"Lesson 3.3: High-Fidelity Rendering with Unity","docId":"chapter-03-digital-twin-gazebo-unity/lesson-3-3-high-fidelity-rendering-with-unity","unlisted":false}]},{"type":"category","label":"Chapter 4: AI-Robot Brain (NVIDIA Isaac)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robotics-book/docs/chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-1-isaac-sim-overview","label":"Lesson 4.1: Isaac Sim Overview","docId":"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-1-isaac-sim-overview","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-2-isaac-ros-for-navigation","label":"Lesson 4.2: Isaac ROS for Navigation","docId":"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-2-isaac-ros-for-navigation","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-3-reinforcement-learning","label":"Lesson 4.3: Reinforcement Learning & Sim-to-Real Transfer","docId":"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-3-reinforcement-learning","unlisted":false}]},{"type":"category","label":"Chapter 5: Vision-Language-Action (VLA)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robotics-book/docs/chapter-05-vision-language-action-vla/lesson-5-1-llm-integration","label":"Lesson 5.1: LLM Integration","docId":"chapter-05-vision-language-action-vla/lesson-5-1-llm-integration","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-05-vision-language-action-vla/lesson-5-2-voice-to-action-with-whisper","label":"Lesson 5.2: Voice-to-Action with Whisper","docId":"chapter-05-vision-language-action-vla/lesson-5-2-voice-to-action-with-whisper","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-05-vision-language-action-vla/lesson-5-3-cognitive-planning","label":"Lesson 5.3: Cognitive Planning & Multi-modal Interaction","docId":"chapter-05-vision-language-action-vla/lesson-5-3-cognitive-planning","unlisted":false}]},{"type":"category","label":"Chapter 6: Capstone Project","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/robotics-book/docs/chapter-06-capstone-project/lesson-6-1-autonomous-humanoid-overview","label":"Lesson 6.1: Autonomous Humanoid Overview","docId":"chapter-06-capstone-project/lesson-6-1-autonomous-humanoid-overview","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-06-capstone-project/lesson-6-2-integration-of-modules","label":"Lesson 6.2: Integration of Modules","docId":"chapter-06-capstone-project/lesson-6-2-integration-of-modules","unlisted":false},{"type":"link","href":"/robotics-book/docs/chapter-06-capstone-project/lesson-6-3-deployment-assessment","label":"Lesson 6.3: Deployment & Assessment","docId":"chapter-06-capstone-project/lesson-6-3-deployment-assessment","unlisted":false}]},{"type":"link","href":"/robotics-book/docs/intro","label":"Introduction","docId":"intro","unlisted":false}]},"docs":{"chapter-01-introduction-to-physical-ai/lesson-1-1-what-is-physical-ai":{"id":"chapter-01-introduction-to-physical-ai/lesson-1-1-what-is-physical-ai","title":"Lesson 1.1: What is Physical AI","description":"Physical AI refers to artificial intelligence systems that interact with the real world through physical bodies, sensors, and actuators. Unlike traditional AI, which exists only as software, Physical AI combines cognition, perception, and action in a single system.","sidebar":"tutorialSidebar"},"chapter-01-introduction-to-physical-ai/lesson-1-2-embodied-intelligence":{"id":"chapter-01-introduction-to-physical-ai/lesson-1-2-embodied-intelligence","title":"Lesson 1.2: Embodied Intelligence","description":"Embodied Intelligence is the principle that intelligence emerges through interaction between a body and its environment. Physical AI leverages this by combining sensors, actuators, and AI algorithms in a feedback loop.","sidebar":"tutorialSidebar"},"chapter-01-introduction-to-physical-ai/lesson-1-3-course-overview":{"id":"chapter-01-introduction-to-physical-ai/lesson-1-3-course-overview","title":"Lesson 1.3: Course Overview & Learning Outcomes","description":"This course introduces students to Physical AI systems and covers:","sidebar":"tutorialSidebar"},"chapter-02-robotic-nervous-system-ros-2/lesson-2-1-ros-2-architecture":{"id":"chapter-02-robotic-nervous-system-ros-2/lesson-2-1-ros-2-architecture","title":"Lesson 2.1: ROS 2 Architecture","description":"ROS 2 (Robot Operating System 2) is a framework for developing robot software. It provides modular architecture, communication infrastructure, and tools for building complex robotic systems.","sidebar":"tutorialSidebar"},"chapter-02-robotic-nervous-system-ros-2/lesson-2-2-nodes-topics-services-actions":{"id":"chapter-02-robotic-nervous-system-ros-2/lesson-2-2-nodes-topics-services-actions","title":"Lesson 2.2: Nodes, Topics, Services, Actions","description":"ROS 2 nodes interact using topics, services, and actions. This enables modular, decoupled robot software that can be scaled.","sidebar":"tutorialSidebar"},"chapter-02-robotic-nervous-system-ros-2/lesson-2-3-python-integration":{"id":"chapter-02-robotic-nervous-system-ros-2/lesson-2-3-python-integration","title":"Lesson 2.3: Python Integration","description":"Python is commonly used to write ROS 2 nodes due to its simplicity and rich libraries.","sidebar":"tutorialSidebar"},"chapter-02-robotic-nervous-system-ros-2/lesson-2-4-urdf-for-humanoids":{"id":"chapter-02-robotic-nervous-system-ros-2/lesson-2-4-urdf-for-humanoids","title":"Lesson 2.4: URDF for Humanoids","description":"URDF (Unified Robot Description Format) is an XML-based format used to describe the structure and properties of robots in ROS 2. It allows simulation, visualization, and integration of humanoid robots in Gazebo or RViz.","sidebar":"tutorialSidebar"},"chapter-03-digital-twin-gazebo-unity/lesson-3-1-gazebo-simulation-basics":{"id":"chapter-03-digital-twin-gazebo-unity/lesson-3-1-gazebo-simulation-basics","title":"Lesson 3.1: Gazebo Simulation Basics","description":"Gazebo is a powerful 3D robotics simulator that allows testing and development of robots in virtual environments before deploying to the real world.","sidebar":"tutorialSidebar"},"chapter-03-digital-twin-gazebo-unity/lesson-3-2-sensor-simulation":{"id":"chapter-03-digital-twin-gazebo-unity/lesson-3-2-sensor-simulation","title":"Lesson 3.2: Sensor Simulation (LiDAR, Cameras, IMU)","description":"Simulating sensors in Gazebo or Unity allows testing perception and control algorithms without a real robot.","sidebar":"tutorialSidebar"},"chapter-03-digital-twin-gazebo-unity/lesson-3-3-high-fidelity-rendering-with-unity":{"id":"chapter-03-digital-twin-gazebo-unity/lesson-3-3-high-fidelity-rendering-with-unity","title":"Lesson 3.3: High-Fidelity Rendering with Unity","description":"High-fidelity rendering ensures robots and environments look realistic, which helps in visualization, debugging, and AI perception development.","sidebar":"tutorialSidebar"},"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-1-isaac-sim-overview":{"id":"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-1-isaac-sim-overview","title":"Lesson 4.1: Isaac Sim Overview","description":"NVIDIA Isaac Sim is a robotics simulation platform that enables testing AI algorithms in photorealistic 3D environments.","sidebar":"tutorialSidebar"},"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-2-isaac-ros-for-navigation":{"id":"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-2-isaac-ros-for-navigation","title":"Lesson 4.2: Isaac ROS for Navigation","description":"Isaac ROS provides prebuilt ROS 2 packages and nodes for robot navigation, including path planning, mapping, and control.","sidebar":"tutorialSidebar"},"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-3-reinforcement-learning":{"id":"chapter-04-ai-robot-brain-nvidia-isaac/lesson-4-3-reinforcement-learning","title":"Lesson 4.3: Reinforcement Learning & Sim-to-Real Transfer","description":"Reinforcement Learning (RL) allows robots to learn tasks by trial and error in simulation before transferring skills to real robots.","sidebar":"tutorialSidebar"},"chapter-05-vision-language-action-vla/lesson-5-1-llm-integration":{"id":"chapter-05-vision-language-action-vla/lesson-5-1-llm-integration","title":"Lesson 5.1: LLM Integration","description":"Large Language Models (LLMs) can be integrated into robots to enable understanding of natural language commands and reasoning.","sidebar":"tutorialSidebar"},"chapter-05-vision-language-action-vla/lesson-5-2-voice-to-action-with-whisper":{"id":"chapter-05-vision-language-action-vla/lesson-5-2-voice-to-action-with-whisper","title":"Lesson 5.2: Voice-to-Action with Whisper","description":"Voice-to-Action allows robots to understand spoken commands using speech recognition models like Whisper.","sidebar":"tutorialSidebar"},"chapter-05-vision-language-action-vla/lesson-5-3-cognitive-planning":{"id":"chapter-05-vision-language-action-vla/lesson-5-3-cognitive-planning","title":"Lesson 5.3: Cognitive Planning & Multi-modal Interaction","description":"Cognitive planning allows robots to combine multiple sensory inputs and reasoning for complex task execution.","sidebar":"tutorialSidebar"},"chapter-06-capstone-project/lesson-6-1-autonomous-humanoid-overview":{"id":"chapter-06-capstone-project/lesson-6-1-autonomous-humanoid-overview","title":"Lesson 6.1: Autonomous Humanoid Overview","description":"The Capstone Project focuses on building an autonomous humanoid robot by integrating concepts from all previous chapters.","sidebar":"tutorialSidebar"},"chapter-06-capstone-project/lesson-6-2-integration-of-modules":{"id":"chapter-06-capstone-project/lesson-6-2-integration-of-modules","title":"Lesson 6.2: Integration of Modules","description":"Integration combines perception, planning, control, and AI reasoning into a cohesive humanoid system.","sidebar":"tutorialSidebar"},"chapter-06-capstone-project/lesson-6-3-deployment-assessment":{"id":"chapter-06-capstone-project/lesson-6-3-deployment-assessment","title":"Lesson 6.3: Deployment & Assessment","description":"Deployment involves testing the humanoid in real-world scenarios and evaluating performance.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction","description":"This book is designed to guide you through the exciting world of robotics, from basic concepts to advanced simulations and humanoid robot control. Throughout the chapters, you'll explore:","sidebar":"tutorialSidebar"}}}}